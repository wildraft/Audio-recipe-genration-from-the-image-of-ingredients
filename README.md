# Audio-recipe-genration-from-the-image-of-ingredients
Food has always played a paramount role in the human life. Besides being essential for their existence, it’s significant in one’s culture, lifestyle, and well-being. A lot of  everyday time is spent on meal preparation. In today’s fast-paced life, comprehending the what’s and how’s to cook is a tedious task. It becomes challenging when one needs to figure out what to make from the food ingredients present in the kitchen.

To resolve this challenge, team aims to build an app to use deep learning models which can infer recipes based on images of the available ingredients. Previous applications in this domain focus on providing recipes for the given list of ingredients based on the fixed recipes database. This restricts the system's performance to the dataset's size and diversity. Moreover, most studies on recipe generation are focused on a list of written ingredients as input which makes it more time-consuming. The project aims to create a mobile application where a user can input the ingredient images and get back a recipe which includes the title, a list of required ingredients, and instructions to cook in audio and text format. A set of instructions in the form of audio is always convenient, especially when the user has to perform those tasks. The key objectives will be food ingredients images and recipes data collection, developing deep learning models for ingredient recognition, recipe generation, and conversion of text to audio of the generated recipe. 
